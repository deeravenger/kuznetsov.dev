<!doctype html><html dir=ltr lang=ru data-theme=dark><head><title>Дмитрий Кузнецов
|
Синтезируем английскую речь</title><meta charset=utf-8><meta name=generator content="Hugo 0.85.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=description content="
      Как при помощи нейронных сетей можно синтезировать английскую речь, на примере Coqui


    "><link rel=stylesheet href=/css/main.min.beb4ded4d3d7b57eaaf7abaedb95860a68a8e8c2320b688e547ba30ead224a19.css integrity="sha256-vrTe1NPXtX6q96uu25WGCmio6MIyC2iOVHujDq0iShk=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.058b31f17db60602cc415fd63b0427e7932fbf35c70d8e341a4c39385f5f6f3e.css integrity="sha256-BYsx8X22BgLMQV/WOwQn55MvvzXHDY40Gkw5OF9fbz4=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/override.min.c4ef93f99f068d7bfc3b070f7eeddd14b511c6e2b8c1e3ca28449fcfe59cdd1d.css integrity="sha256-xO+T+Z8GjXv8OwcPfu3dFLURxuK4wePKKESfz+Wc3R0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/404.min.8af5cba8db45fcd9bffa951d2cb07c1b34c55055091a151d255d39bc2ccfc919.css integrity="sha256-ivXLqNtF/Nm/+pUdLLB8GzTFUFUJGhUdJV05vCzPyRk=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin=anonymous><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=/posts/text-to-speech/><script type=text/javascript src=/js/anatole-header.min.2a2cd9614b7d007dfbb75e8da19e3a0fa872ceab53c6d000c00b7a0c89b85bfc.js integrity="sha256-KizZYUt9AH37t16NoZ46D6hyzqtTxtAAwAt6DIm4W/w=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Синтезируем английскую речь"><meta name=twitter:description content="Как при помощи нейронных сетей можно синтезировать английскую речь, на примере Coqui"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Синтезируем английскую речь","headline":"Синтезируем английскую речь","alternativeHeadline":"","description":"
      Как при помощи нейронных сетей можно синтезировать английскую речь, на примере Coqui


    ","inLanguage":"ru","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/kuznetsov.dev\/posts\/text-to-speech\/"},"author":{"@type":"Person","name":"Дмитрий Кузнецов"},"creator":{"@type":"Person","name":"Дмитрий Кузнецов"},"accountablePerson":{"@type":"Person","name":"Дмитрий Кузнецов"},"copyrightHolder":{"@type":"Person","name":"Дмитрий Кузнецов"},"copyrightYear":"2022","dateCreated":"2022-12-26T00:00:00.00Z","datePublished":"2022-12-26T00:00:00.00Z","dateModified":"2022-12-26T00:00:00.00Z","publisher":{"@type":"Organization","name":"Дмитрий Кузнецов","url":"https://kuznetsov.dev/","logo":{"@type":"ImageObject","url":"https:\/\/kuznetsov.dev\/favicons\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/kuznetsov.dev\/posts\/text-to-speech\/","wordCount":"649","genre":[],"keywords":["manual","open-source"]}</script><script>(function(b,d,e,a,g){b[a]=b[a]||[],b[a].push({'gtm.start':(new Date).getTime(),event:'gtm.js'});var f=d.getElementsByTagName(e)[0],c=d.createElement(e),h=a!='dataLayer'?'&l='+a:'';c.async=!0,c.src='https://www.googletagmanager.com/gtm.js?id='+g+h,f.parentNode.insertBefore(c,f)})(window,document,'script','dataLayer','GTM-KJG8966')</script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KJG8966" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><header><div class="page-top
."><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></a><nav><ul class=nav__list id=navMenu><div class=nav__links><li><a href=/ title>Блог</a></li><li><a href=/posts/ title>Архив блога</a></li><li><a href=/edu/ title>Учеба</a></li><li><a href=/public/ title>Публичка</a></li></div><ul></ul></ul></nav></div></header><div class=wrapper><aside><div class="sidebar
."><div class=sidebar__content><div class=logo-title><div class=title><img src=/avatar-ai.jpg alt="profile picture"><h3 title><a href=/>Дмитрий Кузнецов</a></h3><div class=description><p>[Культ Качества]</p></div></div></div><ul class=social-links><li><a href rel=me aria-label title><i class=fa-2x aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/kuznetsovdy rel=me aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin-in fa-2x" aria-hidden=true></i></a></li><li><a href=https://github.com/dmkuznetsov rel=me aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li><a href=https://t.me/kuznetsov_dev rel=me aria-label=Telegram title=Telegram><i class="fab fa-telegram-plane fa-2x" aria-hidden=true></i></a></li><li><a href=https://twitter.com/kuznetsovdy rel=me aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer--sidebar"><div class=by_farbox><ul class=footer__list><li class=footer__item>&copy;
Дмитрий Кузнецов
2022</li></ul></div></footer><script type=text/javascript src=/js/medium-zoom.min.71100d84fab0ad794b8399a66ac810700cc78d703f715dc10af4d7ba7b761362.js integrity="sha256-cRANhPqwrXlLg5mmasgQcAzHjXA/cV3BCvTXunt2E2I=" crossorigin=anonymous></script></div></aside><main><div class=autopagerize_page_element><div class=content><div class="post
."><div class=post-content><div class=post-title><h1>Синтезируем английскую речь</h1></div><p>На прошлой неделе меня попросили записать видео-инструкцию и озвучить ее на английском языке, чтобы можно было поделиться
этим с интеграторами.
Я написал текст и попытался бодро озвучить видео несколько раз, но акцент и не самая беглая речь давали
результат, которым я не был доволен.
Чтобы не мучать себя и слушателей, я нашел сервис, который сам озвучивает текст с чувством, толком, расстановкой. Внес туда написанный
текст, скачал полученную звуковую дорожку, наложил на видео и остался доволен смотнированным результатом.</p><p>Все это меня натолкнуло на то, что, конечно же, нужно прокачивать язык. А еще неплохо задокументировать
те знания и эксперименты, которые я проводил с использованием Text-to-Speech.</p><h2 id=что-такое-text-to-speech>Что такое Text-to-Speech?</h2><p>Наверняка многие из вас сталкивались с роботизированной озвучкой: в google translate, любимой онлайн-школе английского
языка, игре или приложении. Это технология Text-to-Speech (TTS), которая буквально преобразовывает текст в речь.</p><p>Сама технология не нова и используется уже много лет. Но как и любая технология - она развивалась постепенно.
Голоса современных помощников типа Алисы уже сложно отличить от человеческого, но за этим скрывалось
колосальное количество работы.</p><p>Сейчас для того, чтобы использовать Text-to-Speech в своем приложении достаточно выбрать онлайн-сервис, который
предоставляет эти услуги, например:</p><ul><li><a href=https://cloud.yandex.ru/services/speechkit>Яндекс.Speechkit</a> классно говорит по русски, но отвратительно звучит на английском;</li><li><a href=https://aws.amazon.com/ru/polly/>Amazon Polly</a> выдает очень хорошую озвучку на английском (а может и на других языках, я не проверял).</li></ul><p>Есть и другие сервисы. И все они прекрасно справляются со своими задачами, если понимать их ограничения:</p><ul><li>невозможность кэширования результата;</li><li>невозможность использования внешних сервисов из-за соображениий безопасности;</li><li>невозможность оплатить внешний сервис;</li><li>озвучка может звучать ужасно.</li></ul><h2 id=что-делать-если-невозможно-использовать-внешний-сервис>Что делать, если невозможно использовать внешний сервис?</h2><p>Есть несколько основных вариантов, как организовать озвучку на сайте или в приложении:</p><ol><li>Используя встроенные средства мобильной платформы;</li><li>Используя встроенные средства браузера;</li><li>Заказать предобученную модель;</li><li>Найти предобученную модель в open source.</li></ol><p>У первых двух вариантов качество речи оставляет желать лучшего, но если хочется запилить прототип - то это самое простое и быстрое решение.</p><p>Говоря о заказе моделей, я нашел несколько компаний, которые занимаются синтезом и распознованием речи, а также создают модели под
конкретные нужды, например, голоса для игр. Я пообщался с компанией Silero, у них есть классные
<a href=https://habr.com/ru/users/snakers4/posts/>статьи на Хабре</a>, а так же <a href=https://t.me/silero_voice_bot>бот в телеге</a>,
где можно генерировать разные фразочки разными голосами, например героев из WarCraft.
Вариант использования проприетарных решений хорош, если вы понимаете, что это даст буст вашему бизнесу или сэкономит
операционные расходы.</p><p>Что касается поиска моделей в open source - это сплошная головная боль. Все в основном сделано для датасаентистов -
установи питон, установи кучу пакетов, обучи модель. Практически все, что нашел из предобученного: либо не работало, либо
давало не тот результат, который бы хотелось. Порог входа - высокий.</p><p>Но в один момент я наткнулся на <a href=https://github.com/coqui-ai/TTS>🐸 Coqui</a>, который оказался развивающимся форком технологии от
<a href=https://github.com/mozilla/TTS>Mozilla</a> с предобученными моделями в комплекте и хорошим произношением на английском.
Насколько я понял, самые лучшие результаты базировались на использовании модели <a href=https://github.com/NVIDIA/tacotron2>Tacotron</a>
от NVIDIA.</p><p>Я был крайне впечатлен <a href=http://erogol.com/ddc-samples/>сэмплами</a> и, вместо изучения английского,
решил попробовать развернуть и потестировать модель.</p><h2 id=тестируем--coqui>Тестируем 🐸 Coqui</h2><p>Чтобы собрать такой простой <code>docker-compose.yml</code> пришлось потратить не один час, так как было несколько вариантов,
как запустить модель. К счастью кокуй уже публикует образы, в которые сразу же включена страничка для тестирования.</p><pre><code>---
version: '3.5'

services:
    tts:
    image: ghcr.io/coqui-ai/tts-cpu:latest
    restart: always
    ports:
        - &quot;5002:5002&quot;
    entrypoint: [&quot;python3&quot;, &quot;TTS/server/server.py&quot;, &quot;--model_name&quot;, &quot;tts_models/en/ljspeech/tacotron2-DDC&quot;]
    volumes:
        - .:/root/.local/share/tts
</code></pre><p>И развернул у себя для тестов.</p><p><img src=coqui.jpg alt="🐸 Coqui"></p><p>Модель говорит чистым женским голосом и распространяется по лицензиям, которые позволяют использовать ее в
коммерческих целях в том числе (это естественно лучше всегда перепроверять самостоятельно).</p><p>К слову, Coqui идет с 20 моделями, так что можете поэкспериментировать:</p><pre><code># Запускаете образ локально
docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu

# Вывести на экран список доступных моделей
python3 TTS/server/server.py --list_models

# Запускаете сервер с понравившейся моделью
python3 TTS/server/server.py --model_name tts_models/en/ljspeech/tacotron2-DDC
</code></pre><h2 id=прежде-чем-использовать>Прежде чем использовать</h2><p>Приведенный пример в этой статье - это не production-вариант.
Чтобы использовать ее в продакшене - нужно, как минимум, настроить кэш. А как максимум - прочитать советы по оптимизации
(в документации они были).</p><p>Потестировать модель можно тут: <a href=https://tts.kuznetsov.dev/>https://tts.kuznetsov.dev/</a></p></div><div class=post-footer><div class=info><span class=separator><a class=tag href=/tags/manual/>manual</a><a class=tag href=/tags/open-source/>open-source</a></span></div></div></div></div></div></main></div><footer class="footer footer--base"><div class=by_farbox><ul class=footer__list><li class=footer__item>&copy;
Дмитрий Кузнецов
2022</li></ul></div></footer><script type=text/javascript src=/js/medium-zoom.min.71100d84fab0ad794b8399a66ac810700cc78d703f715dc10af4d7ba7b761362.js integrity="sha256-cRANhPqwrXlLg5mmasgQcAzHjXA/cV3BCvTXunt2E2I=" crossorigin=anonymous></script></body></html>